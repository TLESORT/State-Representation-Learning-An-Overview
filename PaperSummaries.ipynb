{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template\n",
    "*Authors* [pdf](www.google>fr)\n",
    "\n",
    "### Classification for overview\n",
    "\n",
    "### Goal\n",
    "\n",
    "\n",
    "### Method\n",
    "\n",
    "### Related Work\n",
    "- link between the papers<br>\n",
    "**Paper** [pdf](link) <br>\n",
    "\n",
    "\n",
    "### Experiment\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "*********************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relational models\n",
    "These models learn concepts as entities of the world and relational properties of theirs.\n",
    "\n",
    "Towards Deep Symbolic Reinforcement Learning, Garnelo et al. NIPS 2016.\n",
    "Handles three main components of neural-symbolic hybrid systems: 1)Conceptual abstraction. 2) Compositional structure. 3) Common sense priors, i.e., one of the first works bridging the gap among logics and neural models.\n",
    "\n",
    "Relational Networks (Santoro’17) and Visual Interaction Networks (Watters’17) are two philosophically similar models that use abstract logic to reason about the world. Relational reasoning is very closely linked to the elusive human \"common sense\", something that for a long time we thought not even other animals could do (eg \"what is the color of the object closest to the red square?\" \"How many objects have the same shape as the blue one?\"). Now this system achieves higher accuracy than humans.  [1706.01427] A simple neural network module for relational reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slow Feature Analysis : Unsupervised Learning of Invariances (2002)\n",
    "\n",
    "**\n",
    "\n",
    "\n",
    "This paper present the SFA methiod in order to find invariant features inside varying temporal signals.\n",
    "The approach is based on non linear expension of the signal with application of PCA.  The solution is gqrqnteed to find the optimal solution within a particular family of function. The feature exctracted by this method can be ordered by degree of invariance.\n",
    "Unfortunately the perfrormance decrease when the network ios trained to learn several features simultaneously but the result can be use in classification and recognition tasks.\n",
    "\n",
    "This paper present a first step into slow feature learning, it does not present scability to input dimension, the limitation and consequence of using SFA in hierqachical NN (even if an experience about it is done in the paper). The experement are not achieved with real images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Slow Feature Analysis\n",
    "\n",
    "*Varun Raj Kompella, Matthew Luciw, and Jurgen Schmidhuber*\n",
    "\n",
    "First use of the SFA framework into an online fashion thanks to a combination of PCA and MCA (Minor composant analysis). They also extend their work to hierarchical neurla networks an d use them for experiementing high dimensional video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A new embedding quality assement method for manifold learning\n",
    "\n",
    "Introduction of Normalization Independent Embedding Quality Assessment (NIEQA). Compared with current assessment methods which are limited to isometric embeddings, the NIEQA method has a much larger application range due to two features. \n",
    "- First,   it   is   based   on   a   new   measure   which   can   effectively evaluate  how  well  local  neighborhood  eometry  is  preserved under  normalization,  hence  it  can  be  applied  to  both  isometric and  normalized  embeddings.\n",
    "\n",
    "- Second,  it  can  provide  both  local and global evaluations to output an overall assessment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Label-Free Supervision of Neural Networks with Physics and Domain Knowledge\n",
    "*Russell Stewart , Stefano Ermon* [pdf](https://arxiv.org/pdf/1609.05566.pdf)\n",
    "\n",
    "### Classification for overview\n",
    "**Out of the scope** but related to prior learning because it use prior about physics.\n",
    "\n",
    "### Goal\n",
    "We are able to train a convolutional neural network to detect and track objects without any labeled examples\n",
    "\n",
    "\n",
    "### Method\n",
    "We introduce a new approach to supervising neural networks by specifying constraints that should hold over the output space, rather than direct examples of input-output pairs.  These constraints are derived from prior domain knowledge, e.g., from known laws of physics.\n",
    "\n",
    "### Related Work\n",
    "- unsupervised deep learning to construct high level compressed embeddings of images without using label<br>\n",
    "**Learning Compact Binary Descriptors with Unsupervised Deep Neural Networks** [pdf](http://www.iis.sinica.edu.tw/~kevinlin311.tw/cvpr16-deepbit.pdf) <br>\n",
    "**Fast Training of Triplet-based Deep Binary Embedding Networks** [pdf](https://arxiv.org/pdf/1603.02844)<br>\n",
    "\n",
    "- The Deep Q-Network (DQN) provides another inspirational example for training neural networks with constraints rather than direct label<br>\n",
    "**Playing Atari with Deep Reinforcement Learning** [pdf](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf)<br>\n",
    "\n",
    "### Experiment\n",
    "- Tracking the position of a walking man\n",
    "- Detecting objects with causal relationships\n",
    "\n",
    "\n",
    "### Conclusion\n",
    "Our approach can significantly reduce the need for labeled training data, but introduces new challenges for encoding prior knowledge into appropriate loss functions. \n",
    "\n",
    "\n",
    "*************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Learning State Representations with Robotic Priors\n",
    "*Rico Jonschkowski Oliver Brock* [pdf](https://pdfs.semanticscholar.org/dc93/f6d1b704abf12bbbb296f4ec250467bcb882.pdf)\n",
    "\n",
    "### Classification for overview\n",
    "\n",
    "- Learning a state\n",
    "- Learning with priors (physicxs andf robotics)\n",
    "\n",
    "\n",
    "### Goal\n",
    "\n",
    "Learning state representation with robotics priors to use the; with reinforcement learning afterwards\n",
    "\n",
    "### Method\n",
    "\n",
    "### Related Work\n",
    "- Share the term of prior with <br>\n",
    "** Representation learning: A review and new perspectives.** [pdf](link) <br>\n",
    "\n",
    "- Robotic task solved by RL <br>\n",
    "**Reinforcement  learning  in  robotics:  A  survey**\n",
    "\n",
    "- use of robotics priors to learn forward model (or transition function)\n",
    "**A physics-based model prior for object-oriented  MDPs**\n",
    "\n",
    "\n",
    "### Experiment\n",
    "\n",
    "We test how well our method can map 768-dimensional visual observations (16×16 pixels for red, green, and blue) into a two-dimensional or five-dimensional state space.\n",
    "\n",
    "### Conclusion\n",
    "The first key idea to this approach is to focus on state representation learning in the physical world instead of trying to solve the general problem of state representation learning in arbitrary (artificial) environment <br>\n",
    "We also show that the state representations learned by our method greatly improve generalization in reinforcement learning.\n",
    "\n",
    "*********************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A physics-based model prior for object-oriented  MDPs\n",
    "*Authors* [pdf](www.google>fr)\n",
    "\n",
    "### Classification for overview\n",
    "\n",
    "- Learning a forward model (next step)\n",
    "\n",
    "### Goal\n",
    "\n",
    "In  this paper we are primarily interested in the transition model T of a MDP ( Markov Decision Processes), and will consider several possible model priors P(T).\n",
    "Our results show that this representation can result in much faster learning,  by virtue of its strong but appropriate inductive bias in physical environments.\n",
    "\n",
    "### Method\n",
    "\n",
    "In this paper we presented two physics-inspired approaches to  modeling  object  dynamics  for  physical  domains.    The first,  OO-LWR,  leveraged  only  the  geometric  properties of  physical  dynamics,  and  the  second  extended  this  by exploiting modern physical simulation methods.   Our results suggest that PBRL has a learning bias which is well matched to RL tasks in physical domains.\n",
    "\n",
    "### Related Work\n",
    "- estimating physical parameters from data in robotics\n",
    "    - in vision\n",
    "**Model-based estimation of 3d human motion.** <br>\n",
    "**Motion estimation using physical simulatio** <br>\n",
    "    - in graphics for data-driven tuning of simulation parameter <br>\n",
    "**Computing the physical parameters of rigid-body motion from video** <br>\n",
    "**Estimating cloth simulation parameters from vide** <br>\n",
    "**Learning physics-based  motion  style  with  nonlinear  inverse  optimization.** <br>\n",
    "\n",
    "- controlling an initially unknown system and estimating its relevant parameters online <br>\n",
    "**Adaptive control: algorithms, analysis and applications** <br>\n",
    "*Adaptation  is  typically  done  in two  stages.   In  the  first  stage,  the  dynamical  system  parameters are estimated using a Parameter Adaptation Algorithm (PAA). In the next stage, these parameter estimates are used to update the controlle*\n",
    "### Experiment\n",
    "\n",
    "Our results show that PBRL is considerably more sample efficient than OO-LWR, potentially leading to qualitatively different behavior on large physical system.  OO-LWR, a generalization of OO-MDP that uses Locally-Weighted Regression as a core dynamics model. \n",
    "\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The first,  OO-LWR,  leveraged  only  the  geometric  properties of  physical  dynamics,  and  the  second  extended  this  by exploiting modern physical simulation methods.   Our results suggest that PBRL ( Physics Based  Reinforcement Learning) has a learning bias which is well matched to RL tasks in physical domains.\n",
    "\n",
    "*********************************\n",
    "\n",
    "\n",
    "(from **Learning State Representations with Robotic Priors**) \n",
    "Instead of using a generic hypothesis space for the forward model, they use a restricted parametric hypothesis  space  based  on  physics.  This  can  be  very  helpful  for robotic tasks because we know that the right forward model must  lie  in  this  restricted  hypothesis  space.  However,  this work  assumes  to  already  have  a  suitable  state  representation  consisting  of  poses  and  velocities  as  well  as  knowledge  about  the  exact  semantics  of  every  state-dimension.\n",
    "\n",
    "\n",
    "*********************************\n",
    "\n",
    "*********************************\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PVEs : Position-Velocity Encoders for UnsupervisedLearning of Structured State Representations\n",
    "*Rico Jonschkowski, Roland Hafner, Jonathan Scholz, and Martin Riedmiller* [pdf](https://arxiv.org/pdf/1705.09805.pdf)<br> \n",
    "\n",
    "### Classification for overview\n",
    "\n",
    "- Learning a state\n",
    "\n",
    "### Goal\n",
    "\n",
    "We propose position-velocity encoders (PVEs) which learn—without supervision—to encode images to positions  and velocities of task-relevant objects. \n",
    "\n",
    "### Method\n",
    "\n",
    "In  contrast  to  autoencoders,  position-velocity  encoders  are  not  trained  by  image  reconstruction, but by making the position-velocity representation consistent with priors about interacting with the physical world.\n",
    "\n",
    "### Related Work\n",
    "- Robotics Priors (physically grounded)<br>\n",
    "**Learning State Representations with Robotic Priors**<br>\n",
    "**A physics-based model prior for object-oriented  MDPs**<br>\n",
    "\n",
    "- use of restriction bias in visual representation \n",
    "    - In the Architecture :\n",
    "        - convolutional nework : **Convolutional  networks for images, speech, and time series**\n",
    "        - spatial transformer network : **Spatial transformer networks**\n",
    "        - spatial softmax : **End-to-end  training  of  deep  visuomotor  policies**\n",
    "        - end-to-end learnable histogram filters **End-to-end learnable  histogram  filters**\n",
    "        *incorporate  the  structure  of  the  Bayes’  filter  algorithm  for recursive  state  estimation*\n",
    "        - SE3-nets : **SE3-nets: Learning rigid body motion using deep neural networks**\n",
    "        *implement  assumptions about rigid body transformations*\n",
    "    - Preference biases expressed indirectly via other learnable functions based on the representation\n",
    "        - learn image reconstruction : **Embed to control: A locally linear latent dynamics model for control from raw images**\n",
    "        - prediction of future state : **Learning  to  filter  with  predictive  state inference  machines** AND **Embed to control: A locally linear latent dynamics model for control from raw images**\n",
    "        - other auxiliary task : **Reinforcement  learning  with unsupervised auxiliary tasks** AND ** Learning  to  navigate  incomplex  environments.**\n",
    "        -  learn symbol grounding : **Learning  grounded  relational  symbols  from  continuous data  for  abstract  reasoning**\n",
    "        - Direct preference biases are also the focus of metric learning, e.g. learning representations of faces using  the  fairly  general  triplet  loss **FaceNet:  A  unified  embedding  for  face  recognition and clustering.**\n",
    "\n",
    "### Experiment\n",
    "- Inverted Pendulum\n",
    "- Cart-Pole\n",
    "- Ball in Cu\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "We applied PVEs to several simulated control tasks from pixels and  achieved  promising  preliminary  results.\n",
    "\n",
    "*********************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images\n",
    "*Manuel Watter Jost Tobias Springenberg Joschka Boedecker Martin Riedmiller* [pdf](https://pdfs.semanticscholar.org/21c9/dd68b908825e2830b206659ae6dd5c5bfc02.pdf)\n",
    "\n",
    "### Classification for overview\n",
    "\n",
    " - learning a state?\n",
    " - learning from control\n",
    "\n",
    "### Goal\n",
    "E2C consists of a deep generative model, belonging to the family of variational autoencoders, that learns to generate image trajectories from a latent space in which the dynamics is constrained to be locally linear. Our model is derived directly from an optimal control formulation in latent space, supports long-term prediction of image sequences and exhibits strong performance on a variety of complex control problems.\n",
    "\n",
    "### Method\n",
    "\n",
    "### Related Work\n",
    "- Survey  on representation learning for control  <br>\n",
    "**Autonomous learning of state representations for control** <br>\n",
    "- deep autoencoders (ignoring state transitions)<br>\n",
    "**Deep auto-encoder neural networks in reinforcement learning**<br>\n",
    "- control based on image streams <br>\n",
    "**Human-level control through deep reinforcement learning**\n",
    "- kernel based\n",
    "**Learning  of  non-parametric  control  policies  with  high-dimensional state features**\n",
    "- deep policy learning for robot control\n",
    "**End-to-end training of deep visuomotor policies.**\n",
    "- **From pixels to torques:  Policy learning with deep dynamical models**\n",
    "*Autoencoders are used to extract a latent representation for control from images, on which a non-linear model of the forward dynamics is learned. Their model is trained jointly and is thus similar to the non-linear E2C variant in our comparison. In contrast to our model, their formulation requires PCA pre-processing and does neither ensure that long-term predictions in latent space do not diverge, nor that they are linearizable.*\n",
    "- VAE family : <br>\n",
    "    - **Auto-encoding variational bayes**\n",
    "    - **Stochastic backpropagation and approximate inference in deep generative models.**\n",
    "    - ** DRAW: A recurrent neural network forimage generation.**\n",
    "    - **Learning stochastic recurrent networks.**\n",
    "- enforcing desired transformations in latent space during learning (such that the data becomes easy to model) <br>\n",
    "    - transforming auto-encoders : **Transforming auto-encoders.**\n",
    "    -  probabilistic models for images : **Nice: Non-linear independent components estimation.** AND **ransformation properties of learned visual representations.**\n",
    "-  learning relations between pairs of images : <br>\n",
    "    - **ynamical binary latent variable models for 3d human pose trackin**\n",
    "    - **Learning to relate images**\n",
    "- state estimation in Markov decision processes\n",
    "    - for a discussion see : **Learning nonlinear dynamic models**\n",
    "    - **Bayesian Forecasting and Dynamic Models**\n",
    "    - **Latent Kullback Leibler control for continuous-state systems using probabilistic graphical models**\n",
    "    \n",
    "\n",
    "### Experiment\n",
    "\n",
    "We evaluate our model on four visual tasks: an agent in a plane with obstacles, a visual version of the\n",
    "classic inverted pendulum swing-up task, balancing a cart-pole system, and control of a three-link\n",
    "arm with larger images.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "We presented Embed to Control (E2C), a system for stochastic optimal control on high-dimensional image streams. Key to the approach is the extraction of a latent dynamics model which is constrained to be locally linear in its state transitions. An evaluation on four challenging benchmarks revealed that E2C can find embeddings on which control can be performed with ease, reaching performance close to that achievable by optimal control on the real system model\n",
    "\n",
    "*********************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning State Representation for Deep Actor-Critic Control\n",
    "*Authors* [pdf](www.google>fr)\n",
    "\n",
    "### Classification for overview\n",
    "\n",
    "### Goal\n",
    "\n",
    "\n",
    "### Method\n",
    "\n",
    "### Related Work\n",
    "- link between the papers<br>\n",
    "**Paper** [pdf](link) <br>\n",
    "\n",
    "\n",
    "### Experiment\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "*********************************\n",
    "\n",
    "\n",
    "Use of the \"predictive prior to learn a task related state representation as a pretraining for the **ML-DDPG** algorithm (Model Learning Deterministic Policy Gradient).\n",
    "\n",
    "the prior aim to predict the next state and reward. It is supervised. :\n",
    "$L_m = ||  s_{t+1} - \\hat{s_{t+1}}  ||^2_2    +  \\lambda_m ||  r_{t+1} - \\hat{r_{t+1}}  ||^2_2 $\n",
    "\n",
    "\n",
    "it allows to train RL faster afterward. ( \"“End-to-end  training of deep visuomotor policies,\" claim it is not possible?)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
