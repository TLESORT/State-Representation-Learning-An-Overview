
# Learning with a priori

## Introduction

~What do I want to say?~
That state represeentation learning can be done with prior

~What does the prior do?~
The prior are a way to share knowledge we have about the wolrd with our deep learning algorithm

~How to do it?~
By constraining the learning process (by architecture or by optimization)

## Learned States

## A priori

- Simplicity
- Time
- Proportionnality
- Repetability
- Causality
- [...]

## Methods

- architecture constrainct
- siamese network + optimization constrainct
- metric learning

## Papers

- [ ] **PVEs: Position-Velocity Encoders for Unsupervised Learning of Structured State Representations**, Rico Jonschkowski, Roland Hafner, Jonathan Scholz, Martin Riedmiller, (2017), pdf, arXiv
- [ ] **Learning State Representations with Robotic Priors**, Rico Jonschkowski, Oliver Brock, (2015) , pdf <br>
- [ ] **A Physics-Based Model Prior for Object-Oriented MDPs** , *Jonathan Scholz, Martin Levihn, Charles L. Isbell, David Wingate*, (2014) [pdf](http://proceedings.mlr.press/v32/scholz14.pdf)  <br>
- [ ](hidden state representation) **The Curious Robot: Learning Visual Representations via Physical Interactions**,Lerrel Pinto, Dhiraj Gandhi, Yuanfeng Han, Yong-Lae Park, Abhinav Gupta,(2016) <br>
- [ ] **Label-Free Supervision of Neural Networks with Physics and Domain Knowledge** , *Russell Stewart , Stefano Ermon*, (2016) <br>
- [ ] **Slow Feature Analysis:Unsupervised Learning of Invariance**, *Laurenz Wiskott, Terrence J. Sejnowski*
