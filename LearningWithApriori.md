
# Learning with a priori

****************************************************

`What do I want to say?`<br>
That state represeentation learning can be done with prior

`What does the prior do?`<br>
The prior are a way to share knowledge we have about the wolrd with our deep learning algorithm

`How to do it?`<br>
By constraining the learning process (by architecture or by optimization)


****************************************************

## Introduction



## Learned States

## A priori

- Simplicity
- Time
- Proportionnality
- Repetability
- Causality
- [...]

## Methods

- architecture constrainct
- siamese network + optimization constrainct
- metric learning

## Papers

- [ ] **PVEs: Position-Velocity Encoders for Unsupervised Learning of Structured State Representations**, Rico Jonschkowski, Roland Hafner, Jonathan Scholz, Martin Riedmiller, (2017), pdf, arXiv
- [ ] **Learning State Representations with Robotic Priors**, Rico Jonschkowski, Oliver Brock, (2015) , pdf <br>
- [ ] **A Physics-Based Model Prior for Object-Oriented MDPs** , *Jonathan Scholz, Martin Levihn, Charles L. Isbell, David Wingate*, (2014) [pdf](http://proceedings.mlr.press/v32/scholz14.pdf)  <br>
- [ ](hidden state representation) **The Curious Robot: Learning Visual Representations via Physical Interactions**,Lerrel Pinto, Dhiraj Gandhi, Yuanfeng Han, Yong-Lae Park, Abhinav Gupta,(2016) <br>
- [ ] **Label-Free Supervision of Neural Networks with Physics and Domain Knowledge** , *Russell Stewart , Stefano Ermon*, (2016) <br>
- [ ] **Slow Feature Analysis:Unsupervised Learning of Invariance**, *Laurenz Wiskott, Terrence J. Sejnowski*
