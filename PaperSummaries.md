Paper Summaries


### Relational and semantic models
These models learn concepts as entities of the world and relational properties of theirs.


Garnelo et al. (2016) proposed an end-to-end reinforcement learning architecture where a neural back end must learn a symbolic representation of its raw data to communicate with the front end.



Towards Deep Symbolic Reinforcement Learning, Garnelo et al. NIPS 2016.
Handles three main components of neural-symbolic hybrid systems: 1)Conceptual abstraction. 2) Compositional structure. 3) Common sense priors, i.e., one of the first works bridging the gap among logics and neural models.

Relational Networks (Santoro’17) and Visual Interaction Networks (Watters’17) are two philosophically similar models that use abstract logic to reason about the world. Relational reasoning is very closely linked to the elusive human "common sense", something that for a long time we thought not even other animals could do (eg "what is the color of the object closest to the red square?" "How many objects have the same shape as the blue one?"). Now this system achieves higher accuracy than humans.  [1706.01427] A simple neural network module for relational reasoning.

On relational learning via programmable agents, where differentiation happens through program execution.
https://arxiv.org/pdf/1706.06383.pdf  
https://www.youtube.com/watch?v=wveUvddFOfA&index=2&list=PLs1LSEoK_daRDnPUB2u7VAXSonlNU7IcV   % Idea to extend Sebastien F's dataset?


